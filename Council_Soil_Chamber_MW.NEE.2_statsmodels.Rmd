---
title: "Council_Soil_Chamber_MW.NEE.2_statsmodel."  #breaking NEE apart by plot type for stats, adapted from NEE_statsmodels.Rmd #only 22 observations for complete cases of MW plot types --> reworked for correlation among predictor variables (3/13/25)
output: html_document
date: "2025-03-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Load libraries 
```{r, include=FALSE}
rm(list= ls())

library(data.table)
library(ggplot2)
library(cowplot)
library(openair)
library(plotrix)
library(signal)
library(svMisc)
library(zoo)
library(stringr)
library(plyr)
library(viridis)
library(lubridate)
library(tidyverse)
library(gridExtra)
library(plotly)
library(RColorBrewer)
library(pracma)
library(dplyr)
library(openair)
library(nlme)
library(lme4)

Sys.setenv(TZ='UTC')

```

#Load filtered and merged df of soil chamber fluxes, moisture, temp (I upload multiples but only using df_NEE_RECO2 and df_NEE_RECO2_GPP for analysis below)
```{r}
# #filtered for p<0.05; units umol/m2/s or nmol/m2/s
# df_soilchambers_filtered = fread('C:/Users/kkent/Documents/Council Data/Soil Chambers_Council/council_filtered_soil_chamber_fluxes_2017to2019.csv')
# 
# #fluxes and moisture/temp df merged; FCO2 in units g/m2/s
# df_fulljoin = fread('C:/Users/kkent/Documents/Council Data/Soil Chambers_Council/council_fulljoin_soilchamber_fluxes_moisttemp_2017to2019.csv')

# *****************Use these two, above are just extra if needed for looking at*********************

#used transparent and opaque chambers to identify NEE and RECO, then merged back together 
df_NEE_RECO2 = fread('C:/Users/kkent/Documents/Council Data/Soil Chambers_Council/council_fulljoin_soilchamber_fluxes_moisttemp_2017to2019.csv')

#calculated GPP (NEE - Reco)
df_NEE_RECO2_GPP = fread('C:/Users/kkent/Documents/Council Data/Soil Chambers_Council/council_NEE_RECO2_GPP_2017to2019.csv')

str(df_MWlongNEE)
```


#Re-shape df into long format 
```{r}
library(tidyr)

#Remove the NAs from inundation 
library(dplyr)
df_NEE_RECO2_GPP<- df_NEE_RECO2_GPP %>%
   filter(!is.na(inundated))


# Reshape the dataframe to long format, choose variables of interest 
df_long <- df_NEE_RECO2_GPP %>%
  select(plot_ID, plot_type, landscape_position, measurement_date, time, date, VWC, air_temp, flux_CO2, flux_CH4, FCH4, NEE, RECO, GPP, inundated, soil_temp_10_cm, soil_temp_15_cm, thawdepth) %>%
  pivot_longer(cols = c(NEE, RECO, GPP), 
               names_to = "flux_type", 
               values_to = "flux_value")


```


#Filter df by landscape position and flux type (GPP, NEE, RECO)

####Create new df for each plot type for analysis 
```{r}
#Make dataset for just MW plottype 

#MW - moisture warming plot types 
df_MWlong <- df_long %>%
  filter(plot_type == "MW")

#Re-arrange by flux type (NEE, GPP, RECO) so you can analyze more easily 

# Sort the dataframe by the flux_type column 
df_EClong <- df_EClong %>% arrange(flux_type)


```

#Filter by NEE 
```{r}
#create a dataset with only NEE, and make sure it uses complete cases 
df_MWlongNEE <- df_MWlong %>%
  filter(flux_type == "NEE")

sum(is.na(df_MWlongNEE$flux_value)) #check for 0's, in this one all the variables of interest have 0 NAs
# Look for missing values & remove / create complete cases dataset if needed
any(is.na(df_MWlongNEE[, c("flux_value", "landscape_position", "inundated", 
                           "soil_temp_10_cm", "thawdepth", "VWC")]))
```

# Categorical Predictors: Variance and normality of categorical predictor variables 
```{r}
# Look at variance and normality within categorical predictor variables 

#Flux and landscape pos
df_variance_landpos <- df_MWlongNEE %>%
  group_by(landscape_position) %>%
  summarize(variance = var(flux_value, na.rm = TRUE))

print(df_variance_landpos)

# Variance plot - flux and landscape pos
ggplot(df_variance_landpos, aes(x = landscape_position, y = variance)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Variance of Flux Value by Landscape Position",
       y = "Variance")
#higher variance in upland landscape position than lowland* --> no slope here 


#Flux and inundated - dropped 2 NAs in inundated
df_variance_inundated <- df_MWlongNEE %>%
  group_by(inundated) %>%
  summarize(variance = var(flux_value, na.rm = TRUE))

print(df_variance_inundated)

# Variance plot - flux and inundated
ggplot(df_variance_inundated, aes(x = inundated, y = variance)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Variance of Flux Value by Inundation",
       y = "Variance")
#higher variance NOT* inundated plots 


# Shapiro-Wilk test for normality across entire dataset
shapiro_test <- shapiro.test(df_MWlongNEE$flux_value)
print(shapiro_test) #p=0.005, does NOT conform to normality assumptions 


# Test normality within each landscape position --> for categorical data, test for normality of the response variable (NEE) within each group defined by the categorical variable
df_MWlongNEE %>%
  group_by(landscape_position) %>%
  summarize(
    shapiro_p = shapiro.test(flux_value)$p.value,
    normal = ifelse(shapiro_p > 0.05, "Yes", "No")
      )
#Results: lowland = yes; upland = no


# Test normality based on inundated --> for categorical data, test for normality of the response variable (NEE) within each group defined by the categorical variable
df_MWlongNEE %>%
  group_by(inundated) %>%
  summarize(
    shapiro_p = shapiro.test(flux_value)$p.value,
    normal = ifelse(shapiro_p > 0.05, "Yes", "No")
      )
#Results: N = no, Y = yes


# Q-Q plot of full dataset 
qqnorm(df_MWlongNEE$flux_value)
qqline(df_MWlongNEE$flux_value, col = "red")


#histograms with density curves by landscape position
ggplot(df_MWlongNEE, aes(x = flux_value, fill = landscape_position)) +
  geom_histogram(aes(y = ..density..), alpha = 0.5, position = "identity", bins = 30) +
  geom_density(alpha = 0.2) +
  facet_wrap(~landscape_position) +
  theme_minimal() +
  labs(title = "Distribution of NEE by Landscape Position")


# histograms with density curves by inundated
ggplot(df_MWlongNEE, aes(x = flux_value, fill = inundated)) +
  geom_histogram(aes(y = ..density..), alpha = 0.5, position = "identity", bins = 30) +
  geom_density(alpha = 0.2) +
  facet_wrap(~inundated) +
  theme_minimal() +
  labs(title = "Distribution of NEE by Inundation")



#homogeneity of variance - levene's test
# p > 0.05: Variances are homogeneous (no significant difference between variances).
# p â‰¤ 0.05: Variances are not homogeneous.
library(car)

# Test homogeneity of variance for categorical predictor factors
leveneTest(flux_value ~ landscape_position, data = df_MWlongNEE) #p=0.15, homogeneity of var is ok
leveneTest(flux_value ~ inundated, data = df_MWlongNEE)#p = 0.15, ok


#for interactions
leveneTest(flux_value ~ landscape_position * inundated, data = df_MWlongNEE) #p=0.15, ok

```

#Continuous predictors: Variance and normality of continuous predictor variables 

###Testing to see which kind of correlation to use: Pearson for parametric, Spearman for non-parametric
```{r}
#test distribution normality of each numeric predictor variable 
shapiro.test(df_MWlongNEE$soil_temp_10_cm) #p=0.13, normal 
shapiro.test(df_MWlongNEE$thawdepth) #p = <0.001, NOT normal *
shapiro.test(df_MWlongNEE$VWC) #p=0.264, normal 

#visualize pairs to see if it looks linear
pairs(df_MWlongNEE[c("soil_temp_10_cm", "thawdepth", "VWC")]) #NOPE 

#So this means for correlations and looking at collinearity, I need to use non-parametric tests 


#Check homogeneity of variance: should see even spread of of points for homogeneity of variance 

# Fit a simple model
simple_model <- lm(flux_value ~ VWC, data = df_MWlongNEE)

# Extract fitted values and residuals
fitted_values <- fitted(simple_model)
residuals <- residuals(simple_model)

# Plot residuals vs. predictor
plot(df_MWlongNEE$VWC, residuals, 
     xlab = "Cont. Pred. Var", ylab = "Residuals",
     main = "Residuals vs. Thaw Depth")
abline(h = 0, lty = 2)

# Create a scale-location plot --> should be randomly scattered with a relatively flat trend line (red) for homogeneity of variance 
plot(simple_model, which = 3)

#thawdepth = not a great spread, no flat trendline, probably not homogeneous 
#soil temp = looks ok with spread, trendline a little bowed but relatively flat 
#VWC = spread looks ok, trendlind has a bit of a hump like for thawdepth...

#Breusch-Pagan test - specifically tests if variance of residuals is constant - want a p > 0.05 for homogeneity of var
library(lmtest)
bptest(simple_model)

#thawdepth = p=0.56, shows there is homogeneity of var 
#soil temp = p = 0.9, suggests homogeneity of var 
#VWC = p = 0.61, suggests homogeneity of var 

```
#Checking colinearity / correlations to determine which variables to use for models 


####I used Pearson corr for parametric distributions first, mistkanely - left code/results in for reference, but moved on to use Spearman, the non-parametric corr test, and need to rebuild the models based on these results**

####Pearson's Corr - parametric (incorrect, but leaving for when there is a parametric dataset)
```{r}
#Couldn't run the full gls model due to singularity - checked for collinearity and it seems all upland plots are not inundated and all lowland plots are inundated, creating a perfect correlation. Need to simplify the model to remove inundated* 

# Check for correlations between numeric predictors - this uses Pearson correlation, which assumes linear relationships and normal distribution among variables
cor_matrix <- cor(df_MWlongNEE[c("soil_temp_10_cm", "thawdepth", "VWC")], 
                 use = "complete.obs")
print(cor_matrix) #this showed no correlations, BUT it was the incorretc test to use, as some of my data was not normally distributed*** that's why the spearman correlation tests below did highlight correlations missed in the cor_matrix 
```

#Non-parametric tests of correlations - spearman's correlation 
```{r}
#Correlation between soil temp and thaw depth 

cor.test(df_MWlongNEE$soil_temp_10_cm, df_MWlongNEE$thawdepth, method="spearman")#p<0.05, SIG* --> shows soil temp and thaw depth are capturing most of the same information / are correlated and one should be removed 
cor.test(df_MWlongNEE$soil_temp_10_cm, df_MWlongNEE$VWC, method="spearman") #not sig,not correlated 
cor.test(df_MWlongNEE$thawdepth, df_MWlongNEE$VWC, method="spearman") #not sig,not correlated 

#Soil temp and thawdepth are correlated and one should be removed*
```


#Checking correlation in categorical variables 
```{r}
# Check for separation in categorical variables
table(df_MWlongNEE$landscape_position, df_MWlongNEE$inundated) #all upland is N, all lowland = Y; highly correlated, should remove one of these variables 


# Create contingency table to examine correlation quantitatively / confirm the separation test above 
cont_table <- table(df_MWlongNEE$landscape_position, df_MWlongNEE$inundated)
print(cont_table)

# Test for association
chisq.test(cont_table) #p<0.001 --> shows correlation
# Or for small sample sizes
fisher.test(cont_table) #p<0.001, shows correlation 

# # Measure strength (if you have the vcd package)
# library(vcd)
# assocstats(cont_table)
```

#Testing models for MW NEE -- use complete cases 

#Step 1: Determine which of the correlated variables to keep
```{r}
# Create competing models with one variable at a time - use "ML" to compare models, use "REML" for fitting final model 
#soil temp and thaw depth were correlated 
model_temp <- gls(flux_value ~ landscape_position + soil_temp_10_cm, 
                 data = df_MWlongNEE, method = "ML")

model_thaw <- gls(flux_value ~ landscape_position + thawdepth, 
                 data = df_MWlongNEE, method = "ML")

model_VWC <- gls(flux_value ~ landscape_position + VWC, 
                 data = df_MWlongNEE, method = "ML")

# Compare with AIC/BIC
AIC(model_temp, model_thaw, model_VWC) #model_temp has lower AIC, but not by much
BIC(model_temp, model_thaw, model_VWC) #model_temp has lower BIC 
#model_VWC least best predictor 
#choose to keep soil temp and remove thawdepth
```
#Step 2: Now, test whether VWC imrpoves model or not 
```{r}
# Keeping soil_temp and removing thawdepth 
model_without_VWC <- gls(flux_value ~ landscape_position + soil_temp_10_cm, 
                        data = df_MWlongNEE, method = "ML")

model_with_VWC <- gls(flux_value ~ landscape_position + soil_temp_10_cm + VWC, 
                     data = df_MWlongNEE, method = "ML")

# Compare
anova(model_without_VWC, model_with_VWC) #without has lower AIC/BIC but the p = 0.5, not sig...so go with the simpler model, and remove VWC, since it does not improve the model significantly 
```
#Step 3: Test if random effect of plot_ID is appropriate
```{r}
# #If not already: Make plot_ID, inundated, landscape_position as factor so they'll work with gls
# df_MWlongNEE$plot_ID = factor(df_MWlongNEE$plot_ID)
# df_MWlongNEE$landscape_position = factor(df_MWlongNEE$landscape_position)
# df_MWlongNEE$inundated = factor(df_MWlongNEE$inundated)

#Use best predictor variable from Step 1, which was soil temp 
#use 'ML' for comparing models 

library(nlme)
#gls - no random effect
model_fixed <- gls(flux_value ~ landscape_position + soil_temp_10_cm, 
                  data = df_MWlongNEE, method = "ML")

#lme - with random effect of plot_ID
model_random <- lme(flux_value ~ landscape_position + soil_temp_10_cm, 
                   random = ~1|plot_ID, 
                   data = df_MWlongNEE, method = "ML")

# Compare
anova(model_fixed, model_random) #no sig diff and AIC/BIC nearly the same, p=0.1, so go for simpler model without random effect 
```
#Step 4: Test for variance structure 
```{r}
# test if adding a variance structure is appropriate 
model_homoscedastic <- gls(flux_value ~ landscape_position + soil_temp_10_cm, 
                          data = df_MWlongNEE, method = "ML")

model_heteroscedastic <- gls(flux_value ~ landscape_position + soil_temp_10_cm, 
                            weights = varIdent(form = ~1|landscape_position),
                            data = df_MWlongNEE, method = "ML")

# Compare
anova(model_homoscedastic, model_heteroscedastic) #p=0.001; hetero has lower AIC/BIC and higher LogLik so we do use a variance structure here * 
```
#Step 5: Try adding VWC (or any remaining non-correlated variables) back in to see if it improves the model (use reduction and addition / reduced models to test if various un-correlated predicors improve the model or not, and favor the simpler model)
```{r}
#soil_temp was best 
model_1var <- gls(flux_value ~ landscape_position + soil_temp_10_cm, 
                 weights = varIdent(form = ~1|landscape_position),
                 data = df_MWlongNEE, method = "ML")

model_2var <- gls(flux_value ~ landscape_position + soil_temp_10_cm + VWC, 
                 weights = varIdent(form = ~1|landscape_position),
                 data = df_MWlongNEE, method = "ML")

# Compare
anova(model_1var, model_2var) #model 2var has lower AIc/BIC and higher LogLik, p <0.001 * add VWC back in* 
```
#Step 6: Double check best correlated var was chosen, with and without extra var 
```{r}
#test soil temp and thawdepth, and with and without VWC

model_soiltemp <- gls(flux_value ~ landscape_position + soil_temp_10_cm, 
                 weights = varIdent(form = ~1|landscape_position),
                 data = df_MWlongNEE, method = "ML")

model_soiltempVWC <- gls(flux_value ~ landscape_position + soil_temp_10_cm + VWC, 
                 weights = varIdent(form = ~1|landscape_position),
                 data = df_MWlongNEE, method = "ML")

model_thawdepth <- gls(flux_value ~ landscape_position + thawdepth, 
                 weights = varIdent(form = ~1|landscape_position),
                 data = df_MWlongNEE, method = "ML")

model_thawdepthVWC <- gls(flux_value ~ landscape_position + thawdepth + VWC, 
                 weights = varIdent(form = ~1|landscape_position),
                 data = df_MWlongNEE, method = "ML")

anova(model_soiltemp, model_soiltempVWC) #soiltempVWC better, p <0.001
anova(model_thawdepth, model_thawdepthVWC) #no sig diff, p=0.1, AIC/BIC nearly the same 
anova(model_soiltemp, model_soiltempVWC, model_thawdepth, model_thawdepthVWC) #confirmed model_soiltempVWC is best
```
#Final model, refit with REML
```{r}
MW.NEE.final <- gls(flux_value ~ landscape_position + soil_temp_10_cm + VWC, 
                 weights = varIdent(form = ~1|landscape_position),
                 data = df_MWlongNEE, method = "REML")
summary(MW.NEE.final) #shows landpos (p=0.021), soil temp, and VWC (p<0.001) are sig
Anova(MW.NEE.final) #all sig 
Anova(MW.NEE.final, type = "II", test.statistic = "F") #all sig 
# Using the standard anova function with F tests
anova(MW.NEE.final, type = "marginal", test = TRUE) #all sig 

library(lsmeans)
lsmeans(MW.NEE.final, adjust = "Tukey", pairwise ~ landscape_position) #p=0.0218 - SIG

```

#Step 7: Test for multicollinearity in model 

####For testing this in models, use VIF test 
```{r}
#variance inflation factor (vif) - vif = 1 = variables are not correlated; between 1 & 5 = moderately correlated,  5 or higher indicates highly correlated & multicollinearity among variables. GVIF is a generalized VIF for categorical variables with more than two levels; the adj VIF gives values for comparing across variables with diff degrees of freedom* --> look at both when assessing collinearity in a model 
library(car)
vif(MW.NEE.final) # all <2, so should be ok! 
```
Plot model residuals and QQplot 
```{r}
#plot model residuals (homogeneity of variance)
plot(MW.NEE.final)

#qqplot to verify normality - this plots the actual model, not the residuals 
qqnorm(MW.NEE.final)

#checking how this QQ plot compares to plots created with normally distributed residuals

op <- par(mar = c(2,2,1,1), mfrow = c(5,5))

# create first qq plot using model residuals
# color it red
qqnorm(residuals(MW.NEE.final), xlab = "", ylab = "", main = "", 
       col = "red")
qqline(residuals(MW.NEE.final))

# now create 24 qq plots using Normal data with sigma(dataset)
for(i in 1:24){
  # rnorm() samples from a Normal distribution  
  d <- rnorm(length(residuals(MW.NEE.final)), 
             mean = 0, sd = sigma(MW.NEE.final))
  qqnorm(d, xlab = "", ylab = "", main = "")
  qqline(d)
}

#doesn't look awful, doesn't look great....have Kyle take a look 

#comparing data QQplot to a normal QQplot and hist 
qqnorm(residuals(MW.NEE.final)) #normality of residuals 
hist(residuals(MW.NEE.final)) 
car::qqPlot(x = residuals(MW.NEE.final)) #shows where residuals breach normal distr
qqPlot(residuals(MW.NEE.final))

```

#Normality of Residuals 
```{r}
# Extract standardized/normalized residuals
std_resid <- residuals(MW.NEE.final, type = "normalized")

# Graphical assessment
par(mfrow = c(1, 2))
# Histogram of residuals
hist(std_resid, main = "Histogram of Standardized Residuals", 
     xlab = "Standardized Residuals", freq = FALSE)
curve(dnorm, add = TRUE, col = "red")

# QQ plot
qqnorm(std_resid, main = "Normal Q-Q Plot")
qqline(std_resid, col = "red")

# Formal test
shapiro_test <- shapiro.test(std_resid)
print(shapiro_test) #for gls final model: p=0.001; normality NOT supported 

```


#Test autocorrelation
```{r}
# Extract normalized residuals from GLS model
residuals_gls <- residuals(MW.NEE.final, type = "normalized")

# Plot the autocorrelation function
acf(residuals_gls, main = "Autocorrelation of Residuals") #want bars of Lag1 and higher to be below the blue-dotted lines of confidence -- ignore Lag0 ** Lag0 represents correlation of residuals with themselves and is always ~1, so this isn't useful and isn't a problem. Lag 1 shows corr between each residual and the prev residual, lag 2 = correlation between resisuals 2 steps apart, etc. **Focus on Lag1 and higher* 

#Result: no apparent autocorrelation -- 
#All bars below the confidence interval dotted line = ok

# Compute lag-1 correlation in residuals - values close to 0 = little/no autocorrelation; value near 1 or -1 suggests sig correlation
cor(residuals_gls[-1], residuals_gls[-length(residuals_gls)]) 
#Result: 0.06, suggests no autocorrelation


```

#Homogeneity of variance 
```{r}
# Plot residuals vs fitted values
par(mfrow = c(1, 1))
plot(fitted(MW.NEE.final), std_resid,
     xlab = "Fitted Values", ylab = "Standardized Residuals",
     main = "Residuals vs Fitted")
abline(h = 0, lty = 2)

# Check residuals by predictor variables
par(mfrow = c(2, 2))
boxplot(std_resid ~ df_MWlongNEE$landscape_position, 
        main = "Residuals by Landscape Position")
abline(h = 0, lty = 2)

boxplot(std_resid ~ df_MWlongNEE$inundated, 
        main = "Residuals by Inundation")
abline(h = 0, lty = 2)

plot(df_MWlongNEE$soil_temp_10_cm, std_resid,
     xlab = "Soil Temperature (10 cm)", ylab = "Standardized Residuals")
abline(h = 0, lty = 2)

#Result: spread isn't as good as we've seen...little wonky 


# Residuals vs. Fitted plot
plot(fitted(MW.NEE.final), std_resid, 
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted Values")
abline(h = 0, col = "red", lty = 2)

# Leveneâ€™s Test for Homogeneity of Variance
library(car)
leveneTest(std_resid ~ df_MWlongNEE$landscape_position) #p=0.7; this says it's ok 

```
#Cook's distance for potential outlier - measure of the influence each observation has on predicted values of a regression model. Considers how far the point is from mean of the predictor variables (leverage) and how far the point is from the predicted value (residual). A high value means an obs has strong influence on regression results; values greater than 1 are considered concerning (potential outlier) and values larger than 4/n (n=sample size) need looking into. 
```{r}
library(influence.ME)  

# Equivalent linear model (needed for leverage/hat values)
lm_model <- lm(flux_value ~ landscape_position + soil_temp_10_cm + VWC, 
               data = df_MWlongNEE)

# Extract standardized residuals
std_resid <- residuals(MW.NEE.final, type = "normalized")

# Approx. Cook's D for GLS (using hatvalues from equivalent lm model)
h <- hatvalues(lm_model)
p <- length(coef(MW.NEE.final))
n <- nrow(df_MWlongNEE) # n = sample size / # of obs - for this plot type n = 22
cook_d_gls <- (std_resid^2 / (p * (1 - h))) * h

# Plot
plot(cook_d_gls, type = "h", main = "Cook's Distance for GLS Model with var structure", 
     ylab = "Cook's Distance")
abline(h = 4/n, col = "red", lty = 2)

# Identify outliers
influential_gls <- which(cook_d_gls > 4/n)
points(influential_gls, cook_d_gls[influential_gls], col = "red", pch = 19)

# Print the influential observations
if(length(influential_gls) > 0) {
  cat("Potentially influential observations (GLS-adjusted):\n")
  print(df_MWlongNEE[influential_gls, ])
}

# Rule of thumb threshold
threshold <- 4/n

# Find indices above threshold
influential <- which(cook_d_gls > threshold)

# View these observations
print(df_MWlongNEE[influential, ])

#Results: this seems to show that Cook's D doesn't identify any points above the threshold of 4/n (4/22 = 0.1818) so there doesn't seem to be a real outlier. 
```

#Identify most influential points 
```{r}
# Sort Cook's distances and find the top 3-5 most influential points
sorted_indices <- order(cook_d_gls, decreasing = TRUE)
top_influential <- sorted_indices[1:22]  # Adjust number as needed, based on number of obs 

# View these observations
print(df_MWlongNEE[top_influential, ])

# Print their Cook's distance values
cat("Cook's distance values for top influential points:\n")
for(i in 1:length(top_influential)) {
  cat(sprintf("Index %d: %.6f\n", top_influential[i], cook_d_gls[top_influential[i]]))
}
```


#Visualizing influential points - table and fig 
```{r}
#Table with Cook's D for each variable 

# Identify the top 5 most influential points by index
sorted_indices <- order(cook_d_gls, decreasing = TRUE)
top_influential <- sorted_indices[1:22]  # n - number of obs 

# Create a data frame that shows the index and Cook's distance value
influential_points <- data.frame(
  Original_Row = top_influential,
  Cooks_Distance = cook_d_gls[top_influential]
)

# Extract the actual observations with all their variables
influential_obs <- df_MWlongNEE[top_influential, ]

# Combine the information
result <- cbind(influential_points, influential_obs)
print(result)


#The red dots only show you which row these obs come from*** NOT an influential rank or Cook's D*

#  visualize thaw depth relationship
plot(df_MWlongNEE$thawdepth, df_MWlongNEE$flux_value,
     main = "NEE vs Thaw Depth with Influential Points Highlighted",
     xlab = "Thaw Depth", ylab = "NEE Flux Value")
points(df_MWlongNEE$thawdepth[top_influential], 
       df_MWlongNEE$flux_value[top_influential],
       col = "red", pch = 19, cex = 1.5)

# Add labels to the influential points
text(df_MWlongNEE$thawdepth[top_influential], 
     df_MWlongNEE$flux_value[top_influential],
     labels = top_influential, pos = 4, col = "red")



# #  visualize landscape position relationship
# plot(df_MWlongNEE$landscape_position, df_MWlongNEE$flux_value,
#      main = "NEE vs Land_pos with Influential Points Highlighted",
#      xlab = "Land_pos", ylab = "NEE Flux Value")
# points(df_MWlongNEE$landscape_position[top_influential], 
#        df_MWlongNEE$flux_value[top_influential],
#        col = "red", pch = 19, cex = 1.5)
# 
# # Add labels to the influential points
# text(df_MWlongNEE$landscape_position[top_influential], 
#      df_MWlongNEE$flux_value[top_influential],
#      labels = top_influential, pos = 4, col = "red")


#  visualize soil temp relationship
plot(df_MWlongNEE$soil_temp_10_cm, df_MWlongNEE$flux_value,
     main = "NEE vs Soil Temp 10cm with Influential Points Highlighted",
     xlab = "Soil temp C", ylab = "NEE Flux Value")
points(df_MWlongNEE$soil_temp_10_cm[top_influential], 
       df_MWlongNEE$flux_value[top_influential],
       col = "red", pch = 19, cex = 1.5)

# Add labels to the influential points
text(df_MWlongNEE$soil_temp_10_cm[top_influential], 
     df_MWlongNEE$flux_value[top_influential],
     labels = top_influential, pos = 4, col = "red")



#  visualize VWC relationship
plot(df_MWlongNEE$VWC, df_MWlongNEE$flux_value,
     main = "NEE vs VWC with Influential Points Highlighted",
     xlab = "VWC", ylab = "NEE Flux Value")
points(df_MWlongNEE$VWC[top_influential], 
       df_MWlongNEE$flux_value[top_influential],
       col = "red", pch = 19, cex = 1.5)

# Add labels to the influential points
text(df_MWlongNEE$VWC[top_influential], 
     df_MWlongNEE$flux_value[top_influential],
     labels = top_influential, pos = 4, col = "red")

#These images show that the main outlier is from the very low NEE fluxes in row 1 of dataset * but since it doesn't seem to violate Cook's D, it's probably not a true outlier, and therefore I'm choosing to keep it for now. 
```

#Stats with final model - because the QQplot is very close to a normal distr, and there's one main outlier throwing off the fit from a small sample size (n=22), going to compare these stats to the robust regression and cross-validate with KW/Spearman one-way tests 
```{r}

# Final MW NEE model: keep all variables except for inundated -  refit with REML 
MW.NEE.final <- gls(flux_value ~ landscape_position + soil_temp_10_cm + VWC, 
                           weights = varIdent(form = ~ 1| landscape_position),
                          data = df_MWlongNEE, method = "REML", na.action = na.omit)
summary(MW.NEE.final) #shows landpos, soil temp, and VWC are sig
anova(MW.NEE.final)#sig diff in soil temp & VWC (p<0.001) but landpos p=0.12

library(lsmeans)
lsmeans(MW.NEE.final, adjust = "Tukey", pairwise ~ landscape_position) #p=0.0218 - SIG


```
#Exploring thaw depth and NEE / binning?
```{r}
library(ggplot2)

# Basic scatterplot with smoothed fit line
ggplot(df_MWlongNEE, aes(x = thawdepth, y = flux_value)) +
  geom_point() +
  geom_smooth(method = "loess") +
  theme_minimal() +
  labs(title = "NEE vs Thaw Depth in MW Plots",
       x = "Thaw Depth", y = "NEE Flux")

# Faceted by landscape position to see if the relationship varies
ggplot(df_MWlongNEE, aes(x = thawdepth, y = flux_value)) +
  geom_point() +
  geom_smooth(method = "loess") +
  facet_wrap(~landscape_position) +
  theme_minimal()


library(effects)

# Get effect of thaw depth while holding other variables constant
thaw_effect <- Effect("thawdepth", MW.NEE.final)
plot(thaw_effect)
```
#thaw bins 
```{r}
# Create bins based on quantiles (equal number of observations)
df_MWlongNEE$thaw_bin <- cut(df_MWlongNEE$thawdepth, 
                            breaks = quantile(df_MWlongNEE$thawdepth, 
                                             probs = c(0, 0.33, 0.67, 1)),
                            labels = c("Shallow", "Medium", "Deep"),
                            include.lowest = TRUE)

# Test differences in NEE between bins
thaw_bin_model <- gls(flux_value ~ thaw_bin + landscape_position + 
                soil_temp_10_cm + VWC,
                 weights = varIdent(form = ~ 1| landscape_position),
                data = df_MWlongNEE, method = "REML")
anova(thaw_bin_model)
summary(thaw_bin_model)

# Visualize
boxplot(flux_value ~ thaw_bin, data = df_MWlongNEE) #inc NEE with inc thaw depth 


```

#SoilTemp bins 
```{r}
# Create bins based on quantiles (equal number of observations)
df_MWlongNEE$soiltemp_bin <- cut(df_MWlongNEE$soil_temp_10_cm, 
                            breaks = quantile(df_MWlongNEE$soil_temp_10_cm, 
                                             probs = c(0, 0.33, 0.67, 1)), #shallow = bottom third of thaw depth values, medium = middle third of thaw depth values, and deep = top third of values 
                            labels = c("Cool", "Warm", "Warmest"),
                            include.lowest = TRUE)

# Test differences in NEE between bins
soiltemp_bin_model <- gls(flux_value ~ soiltemp_bin + landscape_position + VWC + thawdepth,
                 weights = varIdent(form = ~ 1| landscape_position),
                data = df_MWlongNEE, method = "REML")
anova(soiltemp_bin_model)
summary(soiltemp_bin_model)

# Visualize
boxplot(flux_value ~ soiltemp_bin, data = df_MWlongNEE) #inc NEE with inc temp

```
#VWC bins 
```{r}
# Create bins based on quantiles (equal number of observations)
df_MWlongNEE$VWC_bin <- cut(df_MWlongNEE$VWC, 
                            breaks = quantile(df_MWlongNEE$VWC, 
                                             probs = c(0, 0.33, 0.67, 1)), #shallow = bottom third of thaw depth values, medium = middle third of thaw depth values, and deep = top third of values 
                            labels = c("Dry", "Moist", "Wet"),
                            include.lowest = TRUE)

# Test differences in NEE between bins
VWC_bin_model <- gls(flux_value ~ VWC_bin + landscape_position + soil_temp_10_cm + thawdepth,
                 weights = varIdent(form = ~ 1| landscape_position),
                data = df_MWlongNEE, method = "REML")
anova(VWC_bin_model)
summary(VWC_bin_model)

# Visualize
boxplot(flux_value ~ VWC_bin, data = df_MWlongNEE) #no huge variation with VWC bins

```


#Boxplot of NEE and landpos
```{r}
# Visualize
boxplot(flux_value ~ landscape_position, data = df_MWlongNEE) #very little variation in NEE fluxes for lowland
```

#trying to transform mixed pos and neg values
```{r}
# Shifted log transformation
min_val = min(df_MWlongNEE$flux_value)
df_MWlongNEE$flux_shifted = log(df_MWlongNEE$flux_value - min_val + 1)

# Or Yeo-Johnson transformation (handles negative values)
library(bestNormalize)
transformer <- yeojohnson(df_MWlongNEE$flux_value)
df_MWlongNEE$flux_transformed <- transformer$x.t

#testing it with gls model 
MW.NEE.final_trnsf <- gls(flux_transformed ~ landscape_position + soil_temp_10_cm + thawdepth + VWC, 
                           weights = varIdent(form = ~ 1| landscape_position),
                          data = df_MWlongNEE, method = "REML", na.action = na.omit)
anova(MW.NEE.final_trnsf)

#Normality of residuals 
# Extract standardized/normalized residuals
std_resid_trnsf <- residuals(MW.NEE.final_trnsf, type = "normalized")

# Graphical assessment
par(mfrow = c(1, 2))
# Histogram of residuals
hist(std_resid_trnsf, main = "Histogram of Standardized Residuals", 
     xlab = "Standardized Residuals", freq = FALSE)
curve(dnorm, add = TRUE, col = "red")

# QQ plot
qqnorm(std_resid_trnsf, main = "Normal Q-Q Plot")
qqline(std_resid_trnsf, col = "red")

# Normality 
shapiro_test <- shapiro.test(std_resid_trnsf)
print(shapiro_test) #shifted: p = 0.001 -> not normal 
#transformed: p = 0.001, not normal 


#homogeneity of variance 
# Leveneâ€™s Test for Homogeneity of Variance
library(car)
leveneTest(std_resid_trnsf ~ df_MWlongNEE$landscape_position) 
#shifted: p = 0.72, ok 
#transformed: p = 0.72, ok 

#Same results for hifted and transformed data...not normal, need to use non-parametric or some combo

```


#Non-parametric approach 

#### Important to note KW test is the non-parametric equivalent of a one-way anova, so it can only test one variable at a time, and can't test continuous/numeric variables. It also can't incorporate a variance structure. Spearman Correlation can be used for continuous variables*
#testing each var independently isn't ideal because it can't capture what might happen when other variables are included...
```{r}
# Test landscape position effect on NEE
kruskal.test(flux_value ~ landscape_position, data = df_MWlongNEE) #p=0.25, not sig 

#wilcoxon test
# For comparing two landscape positions (unpaired)
wilcox.test(flux_value ~ landscape_position, 
            data = df_MWlongNEE,
            subset = landscape_position %in% c("upland", "lowland"))
# #just testing the bins as factors, just curious
# kruskal.test(flux_value ~ thaw_bin, data = df_MWlongNEE) #p=0.13, not sig 
# kruskal.test(flux_value ~ soiltemp_bin, data = df_MWlongNEE) #0.03 *SIG********************* 
# kruskal.test(flux_value ~ VWC_bin, data = df_MWlongNEE) #0.46, not sig 

# For continuous variables, use Spearman correlation
cor.test(df_MWlongNEE$flux_value, df_MWlongNEE$soil_temp_10_cm, method = "spearman") #p=0.003, SIG******
cor.test(df_MWlongNEE$flux_value, df_MWlongNEE$VWC, method = "spearman") #p=0.65, not sig 
#The spearman results match the findings from the final gls model 
```

#Robust Regression - less sensitive to violations of normality but cannot incorporate variance structure**
```{r}
library(MASS)
robust_model <- rlm(flux_value ~ landscape_position + soil_temp_10_cm + VWC, 
                    data = df_MWlongNEE)
summary(robust_model) #Generally, t-values > |2| suggest significance at approximately the 0.05 level, only soil temp is over 2
anova(robust_model) #doesn't show p but shows F-stat

# Extract coefficients and t-values
coefs <- coef(robust_model)
t_vals <- c(-3.1546503, 1.7078290, 3.7032764,  1.7204622) # From rlm output
df <- 17 # Degrees of freedom from rlm and anova output 

# Calculate p-values from t-stat
p_values <- 2 * pt(abs(t_vals), df, lower.tail = FALSE)
names(p_values) <- names(coefs)
print(p_values) #If this was done correctly, soil temp p=0.015 SIG; the others are not sig 
```
#Anova for robust regression 
```{r}
# Assuming you've already run your robust regression model
robust_model <- rlm(flux_value ~ landscape_position + soil_temp_10_cm + VWC, 
                   data = df_MWlongNEE)
summary(robust_model)
Anova(robust_model, type = "II") #use Anova here, anova is mainly for lm, glm, and some other model types. Anova from car package is designed to handle a wider variety of models, including robust regression, so this is the one we want to use. **only chi-sqr available for robust regression from MASS package* 

```
#Additional exploratory non-parametric approaches...not sure I'll use these....*Ask Kyle


#GEE (generalized estimating equations) - can include continuous and categorical predictors, can incorporate var structure 
```{r}
library(geepack)
gee_model <- geeglm(flux_value ~ landscape_position + soil_temp_10_cm + VWC, 
                    data = df_MWlongNEE, 
                   id = landscape_position, corstr = "unstructured")
summary(gee_model)
anova(gee_model, type = "marginal", test = TRUE)

#Results:
# Analysis of 'Wald statistic' Table
# Model: gaussian, link: identity
# Response: flux_value
# Terms added sequentially (first to last)
# 
#                    Df        X2 P(>|Chi|)    
# landscape_position  1    331011   < 2e-16 ***
# soil_temp_10_cm     1        10   0.00163 ** 
# VWC                 1 115086160   < 2e-16 ***
# ---
# Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

#compare correlation structures: exchangeable means pairs of responses within a group are equally correlated; unstructured allows all correlations to freely var
gee_exch <- geeglm(flux_value ~ landscape_position + soil_temp_10_cm + 
                  thawdepth + VWC, data = df_MWlongNEE, 
                  id = landscape_position, corstr = "exchangeable")

gee_unstr <- geeglm(flux_value ~ landscape_position + soil_temp_10_cm + 
                   thawdepth + VWC, data = df_MWlongNEE, 
                   id = landscape_position, corstr = "unstructured")

#smaller QIC is better - the exchangeable has lower QIC
QIC(gee_exch)
QIC(gee_unstr)
```

#GAM (general additive model)
```{r}
library(mgcv)

# Simple version without weighted var structure 
MW.NEE.gam <- gam(flux_value ~ landscape_position + s(soil_temp_10_cm) + s(VWC), 
                  data = df_MWlongNEE, 
                  method = "REML", 
                  na.action = na.omit)

# Check results
summary(MW.NEE.gam)
#checking residuals 
par(mfrow = c(2,2))
gam.check(MW.NEE.gam) #k index p>0.05 so seems the model complextiy is sufficient 


#doesn't really improve the normality of residuals 
# The k-index check is performing what's called a "basis dimension adequacy check." This is testing whether the k value you've chosen is large enough to capture the true relationship in your data.
# The p-values from this test are interpreted as:# 
# If p < 0.05: There's evidence that k is too small, meaning your smooth term might be missing important patterns
# If p > 0.05: There's no evidence that k is too small, suggesting the current complexity is adequate

```

#Quantile regression 
```{r}
library(quantreg)

MW.NEE.qr <- rq(flux_value ~ landscape_position + soil_temp_10_cm + thawdepth + VWC, 
                data = df_MWlongNEE, 
                tau = 0.5, # median regression, more robust to outliers and non-normal distr
                na.action = na.omit)

summary(MW.NEE.qr)
#Results: confidence intervals essentially at 0 so suggests there's no meaningful effect...? this one feels wonky, I don't understand it well enough to know what might be wrong or how to adjust it...
```


